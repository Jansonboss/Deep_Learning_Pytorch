{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T05:45:39.587635Z",
     "start_time": "2021-10-08T05:45:35.354402Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# type hint\n",
    "from typing import List, Dict, Sequence, Any, Union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Download the Forest Cover Type Dataset by UCI Machine Learning from Kaggle. Create a dataframe with only the forests with cover type 1 or 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T05:45:41.543594Z",
     "start_time": "2021-10-08T05:45:40.686781Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type32</th>\n",
       "      <th>Soil_Type33</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "      <th>Cover_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2596</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>221</td>\n",
       "      <td>232</td>\n",
       "      <td>148</td>\n",
       "      <td>6279</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2590</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>212</td>\n",
       "      <td>-6</td>\n",
       "      <td>390</td>\n",
       "      <td>220</td>\n",
       "      <td>235</td>\n",
       "      <td>151</td>\n",
       "      <td>6225</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2804</td>\n",
       "      <td>139</td>\n",
       "      <td>9</td>\n",
       "      <td>268</td>\n",
       "      <td>65</td>\n",
       "      <td>3180</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>135</td>\n",
       "      <td>6121</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2785</td>\n",
       "      <td>155</td>\n",
       "      <td>18</td>\n",
       "      <td>242</td>\n",
       "      <td>118</td>\n",
       "      <td>3090</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>122</td>\n",
       "      <td>6211</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2595</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>-1</td>\n",
       "      <td>391</td>\n",
       "      <td>220</td>\n",
       "      <td>234</td>\n",
       "      <td>150</td>\n",
       "      <td>6172</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0       2596      51      3                               258   \n",
       "1       2590      56      2                               212   \n",
       "2       2804     139      9                               268   \n",
       "3       2785     155     18                               242   \n",
       "4       2595      45      2                               153   \n",
       "\n",
       "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                               0                              510   \n",
       "1                              -6                              390   \n",
       "2                              65                             3180   \n",
       "3                             118                             3090   \n",
       "4                              -1                              391   \n",
       "\n",
       "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "0            221             232            148   \n",
       "1            220             235            151   \n",
       "2            234             238            135   \n",
       "3            238             238            122   \n",
       "4            220             234            150   \n",
       "\n",
       "   Horizontal_Distance_To_Fire_Points  ...  Soil_Type32  Soil_Type33  \\\n",
       "0                                6279  ...            0            0   \n",
       "1                                6225  ...            0            0   \n",
       "2                                6121  ...            0            0   \n",
       "3                                6211  ...            0            0   \n",
       "4                                6172  ...            0            0   \n",
       "\n",
       "   Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  Soil_Type38  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Soil_Type39  Soil_Type40  Cover_Type  \n",
       "0            0            0           5  \n",
       "1            0            0           5  \n",
       "2            0            0           2  \n",
       "3            0            0           2  \n",
       "4            0            0           5  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Lab1_data/covtype.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T05:45:42.393098Z",
     "start_time": "2021-10-08T05:45:42.173805Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_cover_type = (data[\"Cover_Type\"] == 1) |  (data[\"Cover_Type\"] == 2) \n",
    "data_filtered = data[mask_cover_type].reset_index(drop = True)\n",
    "np.unique(data_filtered.Cover_Type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Do the following to get ready for training:\n",
    "(a) Download the Forest Cover Type Dataset by UCI Machine Learning from Kaggle. Create a dataframe with only the forests with cover type 1 or 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T05:45:43.048870Z",
     "start_time": "2021-10-08T05:45:43.045167Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class Forest_DataSet(Dataset):\n",
    "\n",
    "\tdef __init__(self, df):\n",
    "\t\tself.df = df\n",
    "\t\n",
    "\tdef __len__(self):\n",
    "\t\treturn self.df.shape[0]\n",
    "\t\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\trow = self.df.iloc[idx]\n",
    "\t\tX = torch.tensor(row[:10]).float()\n",
    "\t\ty = torch.tensor(row[-1]).float() - 1 # 2 -> 1; 2 -> 0\n",
    "\t\treturn X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T05:45:43.490485Z",
     "start_time": "2021-10-08T05:45:43.486720Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2804.,  139.,    9.,  268.,   65., 3180.,  234.,  238.,  135., 6121.]),\n",
       " tensor(1.))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Forest_ds = Forest_DataSet(data_filtered)\n",
    "next(iter(Forest_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "(b.) Randomly split your data into a training and validation Dataset object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T05:45:45.090798Z",
     "start_time": "2021-10-08T05:45:44.845922Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train, data_val = train_test_split(data_filtered, test_size = 0.2)\n",
    "data_train, data_val = data_train.reset_index(drop = True), data_val.reset_index(drop = True)\n",
    "train_ds, val_ds = Forest_DataSet(data_train), Forest_DataSet(data_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c.) Create a DataLoader with whatever batch size you desire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T05:45:45.847472Z",
     "start_time": "2021-10-08T05:45:45.797447Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 10]) torch.Size([100]) \n",
      "\n",
      "tensor([[ 2.8920e+03,  0.0000e+00,  5.0000e+00,  3.0000e+01,  1.0000e+00,\n",
      "          1.8380e+03,  2.1300e+02,  2.3100e+02,  1.5600e+02,  9.1200e+02],\n",
      "        [ 3.1470e+03,  2.6400e+02,  1.7000e+01,  2.3400e+02,  5.6000e+01,\n",
      "          3.2210e+03,  1.7600e+02,  2.4600e+02,  2.0800e+02,  1.6080e+03],\n",
      "        [ 3.0180e+03,  6.4000e+01,  8.0000e+00,  3.2400e+02,  4.6000e+01,\n",
      "          5.0940e+03,  2.2800e+02,  2.2400e+02,  1.2900e+02,  4.3350e+03],\n",
      "        [ 3.1900e+03,  1.1500e+02,  9.0000e+00,  4.9200e+02,  5.8000e+01,\n",
      "          3.8200e+02,  2.3600e+02,  2.3200e+02,  1.2700e+02,  8.8200e+02],\n",
      "        [ 3.1690e+03,  2.5200e+02,  3.0000e+00,  5.4000e+02, -3.7000e+01,\n",
      "          4.6600e+02,  2.1300e+02,  2.4100e+02,  1.6600e+02,  1.9430e+03],\n",
      "        [ 3.1700e+03,  3.4900e+02,  8.0000e+00,  3.0000e+02,  3.3000e+01,\n",
      "          2.1060e+03,  2.0600e+02,  2.2700e+02,  1.6000e+02,  7.4100e+02],\n",
      "        [ 2.9200e+03,  1.6200e+02,  8.0000e+00,  3.0000e+02,  4.1000e+01,\n",
      "          1.9920e+03,  2.2800e+02,  2.4200e+02,  1.4700e+02,  1.2180e+03],\n",
      "        [ 2.9580e+03,  6.9000e+01,  1.2000e+01,  3.6500e+02,  8.8000e+01,\n",
      "          1.7450e+03,  2.3300e+02,  2.1600e+02,  1.1300e+02,  2.9050e+03],\n",
      "        [ 3.1890e+03,  2.6000e+01,  1.1000e+01,  1.0410e+03,  1.1600e+02,\n",
      "          2.9510e+03,  2.1500e+02,  2.1500e+02,  1.3600e+02,  2.3290e+03],\n",
      "        [ 3.0930e+03,  3.2200e+02,  2.3000e+01,  5.5300e+02,  4.3000e+01,\n",
      "          3.5050e+03,  1.5500e+02,  2.1000e+02,  1.9100e+02,  1.6150e+03],\n",
      "        [ 3.1460e+03,  2.7900e+02,  1.5000e+01,  7.4100e+02,  2.1700e+02,\n",
      "          6.0340e+03,  1.7900e+02,  2.4100e+02,  2.0100e+02,  1.3500e+03],\n",
      "        [ 3.0290e+03,  3.0100e+02,  4.2000e+01,  4.2600e+02,  1.8600e+02,\n",
      "          1.5050e+03,  7.6000e+01,  1.8500e+02,  2.3000e+02,  9.8300e+02],\n",
      "        [ 3.2180e+03,  2.4100e+02,  5.0000e+00,  6.7000e+01,  1.3000e+01,\n",
      "          3.1320e+03,  2.1100e+02,  2.4400e+02,  1.7100e+02,  1.2520e+03],\n",
      "        [ 2.8960e+03,  2.9000e+02,  3.7000e+01,  7.7100e+02,  5.2300e+02,\n",
      "          8.5900e+02,  9.3000e+01,  2.0600e+02,  2.3800e+02,  2.4830e+03],\n",
      "        [ 2.9030e+03,  2.3100e+02,  3.0000e+00,  1.2000e+02,  7.0000e+00,\n",
      "          5.2470e+03,  2.1500e+02,  2.4200e+02,  1.6500e+02,  5.3460e+03],\n",
      "        [ 2.8540e+03,  1.2700e+02,  5.0000e+00,  4.8400e+02,  8.1000e+01,\n",
      "          2.4320e+03,  2.2800e+02,  2.3700e+02,  1.4300e+02,  2.7210e+03],\n",
      "        [ 3.0980e+03,  6.8000e+01,  4.0000e+00,  3.0000e+01,  0.0000e+00,\n",
      "          2.1600e+03,  2.2400e+02,  2.3100e+02,  1.4200e+02,  2.1800e+03],\n",
      "        [ 2.9470e+03,  1.5300e+02,  1.2000e+01,  1.2000e+02,  1.1000e+01,\n",
      "          1.7390e+03,  2.3400e+02,  2.4100e+02,  1.3600e+02,  5.4700e+02],\n",
      "        [ 2.5490e+03,  7.2000e+01,  3.2000e+01,  2.7700e+02,  1.2600e+02,\n",
      "          8.1600e+02,  2.3700e+02,  1.6100e+02,  3.0000e+01,  8.5400e+02],\n",
      "        [ 2.5810e+03,  9.0000e+00,  1.9000e+01,  3.0000e+01,  6.0000e+00,\n",
      "          1.8840e+03,  1.9500e+02,  1.9900e+02,  1.3700e+02,  1.3830e+03],\n",
      "        [ 2.8240e+03,  3.4400e+02,  2.2000e+01,  1.8000e+02,  5.9000e+01,\n",
      "          1.7930e+03,  1.7000e+02,  1.9900e+02,  1.6400e+02,  1.2910e+03],\n",
      "        [ 3.1820e+03,  1.0400e+02,  1.3000e+01,  5.1300e+02,  1.4400e+02,\n",
      "          4.4300e+02,  2.4100e+02,  2.2300e+02,  1.1000e+02,  1.6730e+03],\n",
      "        [ 3.2050e+03,  1.9900e+02,  2.5000e+01,  2.7000e+02,  9.0000e+00,\n",
      "          1.9780e+03,  2.0300e+02,  2.5200e+02,  1.7000e+02,  3.5290e+03],\n",
      "        [ 2.7550e+03,  8.2000e+01,  7.0000e+00,  2.5500e+02,  3.1000e+01,\n",
      "          2.3780e+03,  2.3000e+02,  2.2800e+02,  1.3200e+02,  6.2370e+03],\n",
      "        [ 3.0220e+03,  3.5000e+01,  1.3000e+01,  6.7000e+01,  3.0000e+00,\n",
      "          1.2150e+03,  2.1800e+02,  2.1100e+02,  1.2600e+02,  1.3200e+03],\n",
      "        [ 2.9650e+03,  2.8400e+02,  7.0000e+00,  2.0100e+02,  4.8000e+01,\n",
      "          3.6600e+03,  2.0000e+02,  2.4000e+02,  1.7900e+02,  1.4710e+03],\n",
      "        [ 3.1960e+03,  1.0300e+02,  3.2000e+01,  3.7100e+02,  1.0700e+02,\n",
      "          1.2630e+03,  2.5300e+02,  1.8200e+02,  3.1000e+01,  1.3020e+03],\n",
      "        [ 2.6640e+03,  3.3000e+02,  2.5000e+01,  6.7000e+01,  1.9000e+01,\n",
      "          1.6780e+03,  1.5200e+02,  2.0000e+02,  1.8300e+02,  1.2960e+03],\n",
      "        [ 3.1010e+03,  1.6000e+01,  1.1000e+01,  2.2800e+02,  8.3000e+01,\n",
      "          4.9150e+03,  2.1100e+02,  2.1700e+02,  1.4200e+02,  2.0730e+03],\n",
      "        [ 3.0400e+03,  3.3200e+02,  1.4000e+01,  2.1600e+02,  5.5000e+01,\n",
      "          2.5550e+03,  1.8800e+02,  2.2200e+02,  1.7300e+02,  1.9220e+03],\n",
      "        [ 3.0900e+03,  2.6500e+02,  1.5000e+01,  1.5000e+02,  2.2000e+01,\n",
      "          1.4890e+03,  1.8000e+02,  2.4600e+02,  2.0400e+02,  1.9440e+03],\n",
      "        [ 3.0750e+03,  1.1100e+02,  1.2000e+01,  2.3400e+02,  6.4000e+01,\n",
      "          3.1550e+03,  2.4000e+02,  2.2700e+02,  1.1600e+02,  2.0120e+03],\n",
      "        [ 2.8620e+03,  3.6000e+01,  2.2000e+01,  3.4200e+02,  9.6000e+01,\n",
      "          2.3890e+03,  2.1200e+02,  1.8700e+02,  1.0200e+02,  4.4600e+02],\n",
      "        [ 2.6260e+03,  3.2600e+02,  5.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          7.3500e+02,  2.0600e+02,  2.3400e+02,  1.6600e+02,  1.4800e+03],\n",
      "        [ 2.9550e+03,  2.9700e+02,  1.1000e+01,  2.8500e+02,  4.0000e+01,\n",
      "          2.9220e+03,  1.8900e+02,  2.3700e+02,  1.8700e+02,  1.5440e+03],\n",
      "        [ 3.0240e+03,  4.9000e+01,  9.0000e+00,  2.3400e+02,  3.8000e+01,\n",
      "          4.7000e+02,  2.2400e+02,  2.2000e+02,  1.3000e+02,  1.4060e+03],\n",
      "        [ 3.1230e+03,  9.6000e+01,  1.1000e+01,  4.3000e+02,  1.0000e+01,\n",
      "          3.5480e+03,  2.3700e+02,  2.2500e+02,  1.1700e+02,  3.1500e+03],\n",
      "        [ 2.9520e+03,  2.8000e+01,  1.1000e+01,  4.8400e+02,  4.3000e+01,\n",
      "          4.7360e+03,  2.1600e+02,  2.1500e+02,  1.3400e+02,  5.4150e+03],\n",
      "        [ 2.9400e+03,  3.2300e+02,  1.5000e+01,  2.2800e+02,  4.3000e+01,\n",
      "          4.3990e+03,  1.8100e+02,  2.2400e+02,  1.8200e+02,  3.6100e+02],\n",
      "        [ 2.9290e+03,  3.0200e+02,  9.0000e+00,  3.3500e+02,  3.3000e+01,\n",
      "          5.4740e+03,  1.9400e+02,  2.3600e+02,  1.8100e+02,  5.3670e+03],\n",
      "        [ 2.6310e+03,  3.5400e+02,  6.0000e+00,  2.8300e+02, -1.5000e+01,\n",
      "          5.2400e+02,  2.0900e+02,  2.2900e+02,  1.5800e+02,  1.7610e+03],\n",
      "        [ 2.9300e+03,  3.9000e+01,  7.0000e+00,  5.1300e+02,  4.6000e+01,\n",
      "          3.1730e+03,  2.2100e+02,  2.2500e+02,  1.4000e+02,  1.9540e+03],\n",
      "        [ 2.9910e+03,  3.1000e+01,  6.0000e+00,  4.2000e+01,  0.0000e+00,\n",
      "          2.6840e+03,  2.1900e+02,  2.2800e+02,  1.4500e+02,  2.0300e+03],\n",
      "        [ 2.9160e+03,  3.0800e+02,  1.6000e+01,  3.6600e+02,  1.1800e+02,\n",
      "          1.7830e+03,  1.7600e+02,  2.2900e+02,  1.9300e+02,  1.0720e+03],\n",
      "        [ 3.2020e+03,  5.1000e+01,  1.0000e+01,  1.0800e+02,  1.2000e+01,\n",
      "          5.7370e+03,  2.2500e+02,  2.1800e+02,  1.2600e+02,  1.3380e+03],\n",
      "        [ 3.1460e+03,  1.1600e+02,  9.0000e+00,  2.7000e+02,  6.5000e+01,\n",
      "          1.3320e+03,  2.3600e+02,  2.3100e+02,  1.2600e+02,  3.2660e+03],\n",
      "        [ 3.1070e+03,  2.5900e+02,  1.7000e+01,  1.9000e+02,  5.1000e+01,\n",
      "          8.1900e+02,  1.7700e+02,  2.4700e+02,  2.0700e+02,  1.4890e+03],\n",
      "        [ 3.0120e+03,  7.3000e+01,  1.3000e+01,  2.6800e+02,  7.9000e+01,\n",
      "          2.0870e+03,  2.3500e+02,  2.1300e+02,  1.0700e+02,  2.3620e+03],\n",
      "        [ 2.9710e+03,  2.7400e+02,  1.3000e+01,  1.7000e+02,  1.0000e+01,\n",
      "          2.4230e+03,  1.8400e+02,  2.4300e+02,  1.9800e+02,  8.4500e+02],\n",
      "        [ 2.8020e+03,  5.1000e+01,  2.5000e+01,  2.4000e+02,  5.9000e+01,\n",
      "          1.2660e+03,  2.2300e+02,  1.7700e+02,  7.4000e+01,  2.2800e+03],\n",
      "        [ 3.0210e+03,  8.2000e+01,  7.0000e+00,  5.7300e+02,  1.7400e+02,\n",
      "          5.6530e+03,  2.3000e+02,  2.2800e+02,  1.3200e+02,  5.0880e+03],\n",
      "        [ 3.1460e+03,  3.9000e+01,  9.0000e+00,  4.2000e+02,  3.7000e+01,\n",
      "          4.2770e+03,  2.2100e+02,  2.2000e+02,  1.3400e+02,  2.0170e+03],\n",
      "        [ 3.2000e+03,  1.1000e+01,  5.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          3.8100e+03,  2.1500e+02,  2.3000e+02,  1.5200e+02,  2.9550e+03],\n",
      "        [ 3.0980e+03,  9.1000e+01,  1.0000e+01,  3.0100e+02,  4.3000e+01,\n",
      "          5.7300e+02,  2.3600e+02,  2.2400e+02,  1.1900e+02,  1.4160e+03],\n",
      "        [ 3.2630e+03,  4.5000e+01,  7.0000e+00,  3.6000e+02, -1.5000e+01,\n",
      "          1.4650e+03,  2.2200e+02,  2.2500e+02,  1.3800e+02,  1.5240e+03],\n",
      "        [ 2.9750e+03,  4.0000e+00,  1.2000e+01,  3.0000e+01,  1.0000e+01,\n",
      "          2.1420e+03,  2.0400e+02,  2.1600e+02,  1.4900e+02,  1.1210e+03],\n",
      "        [ 3.0930e+03,  1.9000e+01,  2.0000e+01,  3.0100e+02,  1.9000e+01,\n",
      "          9.7900e+02,  2.0100e+02,  1.9400e+02,  1.2400e+02,  1.4300e+03],\n",
      "        [ 2.8910e+03,  8.4000e+01,  2.1000e+01,  0.0000e+00,  0.0000e+00,\n",
      "          2.0400e+03,  2.4400e+02,  2.0000e+02,  7.5000e+01,  1.5280e+03],\n",
      "        [ 2.7340e+03,  1.7900e+02,  1.2000e+01,  0.0000e+00,  0.0000e+00,\n",
      "          1.4700e+03,  2.2500e+02,  2.4700e+02,  1.5300e+02,  1.4180e+03],\n",
      "        [ 2.5680e+03,  6.6000e+01,  3.5000e+01,  9.0000e+01,  4.1000e+01,\n",
      "          7.5200e+02,  2.2900e+02,  1.4800e+02,  2.2000e+01,  8.7200e+02],\n",
      "        [ 3.2210e+03,  2.5200e+02,  2.0000e+00,  3.7900e+02,  3.7000e+01,\n",
      "          5.6000e+02,  2.1400e+02,  2.4000e+02,  1.6400e+02,  1.5910e+03],\n",
      "        [ 3.0720e+03,  3.0000e+02,  3.5000e+01,  1.9200e+02,  4.4000e+01,\n",
      "          2.5140e+03,  1.0400e+02,  2.0200e+02,  2.2700e+02,  2.9290e+03],\n",
      "        [ 2.9610e+03,  7.7000e+01,  1.1000e+01,  4.5800e+02,  1.6000e+01,\n",
      "          8.0500e+02,  2.3400e+02,  2.2000e+02,  1.1700e+02,  1.9470e+03],\n",
      "        [ 2.8570e+03,  8.3000e+01,  2.4000e+01,  3.1900e+02,  8.7000e+01,\n",
      "          2.5860e+03,  2.4500e+02,  1.9200e+02,  6.3000e+01,  9.1200e+02],\n",
      "        [ 3.0380e+03,  8.5000e+01,  8.0000e+00,  4.2000e+01,  3.0000e+00,\n",
      "          4.7390e+03,  2.3200e+02,  2.2700e+02,  1.2800e+02,  6.9300e+02],\n",
      "        [ 3.1300e+03,  2.6600e+02,  1.4000e+01,  1.2400e+02,  1.3000e+01,\n",
      "          5.6410e+03,  1.8300e+02,  2.4500e+02,  2.0100e+02,  2.7660e+03],\n",
      "        [ 3.1290e+03,  3.2300e+02,  1.8000e+01,  1.5000e+02,  3.5000e+01,\n",
      "          2.5920e+03,  1.7200e+02,  2.1800e+02,  1.8500e+02,  6.7100e+02],\n",
      "        [ 3.0430e+03,  7.6000e+01,  2.7000e+01,  3.0600e+02,  1.0700e+02,\n",
      "          1.5840e+03,  2.4100e+02,  1.8000e+02,  5.2000e+01,  2.5800e+03],\n",
      "        [ 2.7690e+03,  5.0000e+01,  8.0000e+00,  1.2000e+02,  2.8000e+01,\n",
      "          1.8000e+03,  2.2400e+02,  2.2300e+02,  1.3400e+02,  2.8210e+03],\n",
      "        [ 3.2070e+03,  5.8000e+01,  1.6000e+01,  3.6100e+02,  9.1000e+01,\n",
      "          5.0670e+03,  2.3000e+02,  2.0300e+02,  1.0100e+02,  2.8680e+03],\n",
      "        [ 3.0430e+03,  2.9000e+02,  1.5000e+01,  3.9000e+02,  4.6000e+01,\n",
      "          2.6310e+03,  1.7800e+02,  2.3700e+02,  1.9900e+02,  1.0240e+03],\n",
      "        [ 3.1250e+03,  1.3000e+01,  4.0000e+00,  2.8500e+02,  1.8000e+01,\n",
      "          5.5580e+03,  2.1500e+02,  2.3100e+02,  1.5200e+02,  7.5100e+02],\n",
      "        [ 3.2790e+03,  1.4700e+02,  1.7000e+01,  6.3600e+02,  1.2200e+02,\n",
      "          1.0480e+03,  2.4100e+02,  2.3600e+02,  1.1800e+02,  1.2840e+03],\n",
      "        [ 2.9020e+03,  2.2400e+02,  2.3000e+01,  1.2000e+02, -1.6000e+01,\n",
      "          1.6040e+03,  1.8200e+02,  2.5400e+02,  2.0000e+02,  2.4830e+03],\n",
      "        [ 2.7800e+03,  1.1500e+02,  1.7000e+01,  3.6100e+02,  1.0300e+02,\n",
      "          1.8710e+03,  2.4700e+02,  2.2100e+02,  9.5000e+01,  2.1550e+03],\n",
      "        [ 3.2810e+03,  3.9000e+01,  3.0000e+00,  2.6800e+02,  1.4000e+01,\n",
      "          4.9170e+03,  2.2000e+02,  2.3200e+02,  1.4900e+02,  6.3100e+02],\n",
      "        [ 3.2540e+03,  1.6200e+02,  1.5000e+01,  3.9100e+02,  5.2000e+01,\n",
      "          2.6630e+03,  2.3400e+02,  2.4200e+02,  1.3500e+02,  1.2090e+03],\n",
      "        [ 3.2630e+03,  2.8300e+02,  1.7000e+01,  9.0200e+02,  1.2800e+02,\n",
      "          6.4100e+02,  1.7100e+02,  2.3900e+02,  2.0700e+02,  2.8020e+03],\n",
      "        [ 3.0310e+03,  3.1700e+02,  8.0000e+00,  3.6100e+02,  7.1000e+01,\n",
      "          2.2390e+03,  1.9900e+02,  2.3300e+02,  1.7400e+02,  5.9100e+02],\n",
      "        [ 2.6680e+03,  1.2000e+02,  2.0000e+01,  3.0000e+01,  1.0000e+01,\n",
      "          2.1350e+03,  2.4900e+02,  2.1900e+02,  8.9000e+01,  4.6990e+03],\n",
      "        [ 3.0960e+03,  6.0000e+00,  9.0000e+00,  1.8200e+02,  3.0000e+01,\n",
      "          2.3350e+03,  2.1000e+02,  2.2300e+02,  1.5100e+02,  2.3770e+03],\n",
      "        [ 3.2580e+03,  1.1600e+02,  1.6000e+01,  3.3000e+02,  6.2000e+01,\n",
      "          1.6200e+02,  2.4600e+02,  2.2300e+02,  1.0100e+02,  5.7100e+02],\n",
      "        [ 2.6240e+03,  3.1000e+01,  1.0000e+01,  2.0100e+02,  2.5000e+01,\n",
      "          1.5650e+03,  2.1800e+02,  2.1900e+02,  1.3600e+02,  4.8430e+03],\n",
      "        [ 3.2570e+03,  2.0900e+02,  7.0000e+00,  2.6800e+02, -1.7000e+01,\n",
      "          2.7810e+03,  2.1500e+02,  2.4700e+02,  1.6800e+02,  5.1400e+02],\n",
      "        [ 3.3090e+03,  2.2000e+01,  1.6000e+01,  7.2200e+02,  1.8000e+01,\n",
      "          1.8390e+03,  2.0800e+02,  2.0500e+02,  1.3000e+02,  2.8000e+03],\n",
      "        [ 3.0540e+03,  6.3000e+01,  2.0000e+00,  4.8000e+02,  8.2000e+01,\n",
      "          2.5050e+03,  2.2100e+02,  2.3400e+02,  1.5000e+02,  2.2330e+03],\n",
      "        [ 3.3350e+03,  2.6600e+02,  2.2000e+01,  1.1200e+03,  3.3600e+02,\n",
      "          3.5660e+03,  1.5900e+02,  2.4300e+02,  2.2000e+02,  2.6520e+03],\n",
      "        [ 3.0940e+03,  1.9000e+02,  4.0000e+00,  4.9700e+02,  3.2000e+01,\n",
      "          3.6200e+02,  2.2000e+02,  2.4300e+02,  1.5900e+02,  1.5050e+03],\n",
      "        [ 2.8730e+03,  2.9000e+02,  1.3000e+01,  1.3400e+02, -1.0000e+01,\n",
      "          1.5210e+03,  1.8400e+02,  2.3800e+02,  1.9400e+02,  1.5010e+03],\n",
      "        [ 2.4040e+03,  6.3000e+01,  1.6000e+01,  6.0000e+01,  3.0000e+00,\n",
      "          4.9700e+02,  2.3200e+02,  2.0700e+02,  1.0200e+02,  5.3700e+02],\n",
      "        [ 3.0080e+03,  2.3900e+02,  1.8000e+01,  1.8000e+02,  4.6000e+01,\n",
      "          3.2830e+03,  1.8500e+02,  2.5200e+02,  2.0200e+02,  1.2650e+03],\n",
      "        [ 2.7840e+03,  3.0000e+01,  8.0000e+00,  1.2000e+02,  5.0000e+00,\n",
      "          1.5900e+03,  2.1800e+02,  2.2300e+02,  1.4100e+02,  2.5060e+03],\n",
      "        [ 3.0820e+03,  2.6300e+02,  2.2000e+01,  1.2400e+02,  4.0000e+01,\n",
      "          2.8900e+03,  1.5900e+02,  2.4400e+02,  2.2100e+02,  1.5950e+03],\n",
      "        [ 3.2220e+03,  2.6700e+02,  2.5000e+01,  5.3700e+02,  1.1800e+02,\n",
      "          5.9610e+03,  1.4900e+02,  2.4100e+02,  2.2600e+02,  2.7340e+03],\n",
      "        [ 2.7910e+03,  1.2000e+02,  1.0000e+01,  2.1200e+02,  5.1000e+01,\n",
      "          3.0560e+03,  2.3800e+02,  2.3100e+02,  1.2300e+02,  2.7630e+03],\n",
      "        [ 2.9050e+03,  1.0800e+02,  8.0000e+00,  1.2400e+02,  1.1000e+01,\n",
      "          1.6940e+03,  2.3500e+02,  2.3100e+02,  1.2800e+02,  8.8200e+02],\n",
      "        [ 3.1150e+03,  1.1800e+02,  4.0000e+00,  2.4700e+02,  3.4000e+01,\n",
      "          1.5370e+03,  2.2600e+02,  2.3600e+02,  1.4500e+02,  2.9550e+03],\n",
      "        [ 2.9390e+03,  3.2000e+01,  7.0000e+00,  3.0000e+01,  1.0000e+00,\n",
      "          2.0100e+03,  2.1900e+02,  2.2400e+02,  1.4200e+02,  1.6240e+03],\n",
      "        [ 2.9660e+03,  2.6100e+02,  1.2000e+01,  6.0000e+01,  1.5000e+01,\n",
      "          2.6480e+03,  1.8900e+02,  2.4600e+02,  1.9500e+02,  7.2100e+02],\n",
      "        [ 3.2750e+03,  3.3500e+02,  1.5000e+01,  3.2300e+02,  2.3000e+01,\n",
      "          4.4120e+03,  1.8500e+02,  2.1800e+02,  1.7200e+02,  7.2600e+02]]) tensor([1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1.,\n",
      "        1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
      "        0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 1., 1., 1., 0., 0., 1., 0.])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size = 100, shuffle = True)\n",
    "val_dl = DataLoader(val_ds, batch_size = 100, shuffle = False)\n",
    "\n",
    "x, y = next(iter(train_dl))\n",
    "\n",
    "# notice that since we set batch_size = 10\n",
    "# each time the gradient descent will see this 10 rows of data shape=(10,2)\n",
    "# and then update the gradient and corresponding parameters\n",
    "print(x.shape, y.shape, \"\\n\")\n",
    "\n",
    "print(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Set up the following:\n",
    "\n",
    "(a.) A 3-layer Feed-Forward Neural Network for this data. Think about the size of the input/output layer. Only linear layers and activation functions are allowed right now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T05:45:54.816706Z",
     "start_time": "2021-10-08T05:45:54.814000Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "# from torchsummary import summary\n",
    "\n",
    "class ThreeLayersModel(nn.Module):\n",
    "\n",
    "\tdef __init__(self, input_dim, hidden_dim, output_dim):\n",
    "\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\t\tself.Linear1 = nn.Linear(input_dim, hidden_dim)\n",
    "\t\tself.Linear2 = nn.Linear(hidden_dim, output_dim)\n",
    "\t\tself.relu = nn.ReLU()\n",
    "\n",
    "\t\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.Linear1(x)\n",
    "\t\tx = self.relu(x)\n",
    "\t\tx = self.Linear2(x)\n",
    "\n",
    "\t\treturn torch.squeeze(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T05:46:00.670733Z",
     "start_time": "2021-10-08T05:46:00.668551Z"
    }
   },
   "outputs": [],
   "source": [
    "model = ThreeLayersModel(10, 10, 1) \n",
    "# summary(model, input_size = (10, ), device = \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 4. Write a function that iterates over a dataloader, doing the following: \n",
    "\n",
    "(a.) prints the average loss (average over each datapoint!),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T05:46:01.471381Z",
     "start_time": "2021-10-08T05:46:01.467820Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "model = ThreeLayersModel(10, 10, 1) \n",
    "loss_fun = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.1)\n",
    "\n",
    "def one_epoch_test(model, data_loader, optimizer, loss_fun):\n",
    "\n",
    "\tX, y = next(iter(data_loader))\n",
    "\t\n",
    "\tmodel.train()\n",
    "\ty_pred = model(X)\n",
    "\tloss = loss_fun(y_pred, y)\n",
    "\tprint(\"loss: \", loss.item())\n",
    "\n",
    "\toptimizer.zero_grad()\n",
    "\tloss.backward()\n",
    "\toptimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T05:46:02.236317Z",
     "start_time": "2021-10-08T05:46:02.195831Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  71.24311065673828\n"
     ]
    }
   ],
   "source": [
    "one_epoch_test(model = model, data_loader = train_dl, optimizer = optimizer, loss_fun = loss_fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 5. Write a loop that trains your model for ten epochs, and at the end of each epoch it prints the average loss on the training set and on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T06:11:11.481769Z",
     "start_time": "2021-10-08T06:11:11.476886Z"
    }
   },
   "outputs": [],
   "source": [
    "def one_pass(model: model, data_loader: DataLoader, backward: bool, loss_fun,  optimizer) -> torch.float:\n",
    "\n",
    "\tif backward is True:\n",
    "\t\tmodel.train()\n",
    "\telse:\n",
    "\t\tmodel.eval()\n",
    "\n",
    "\ttotal_loss = 0.0\n",
    "\tfor x, y in data_loader:\n",
    "\t\ty_pred = model(x)\n",
    "\t\tloss = loss_fun(y_pred, y)\n",
    "\t\ttotal_loss += loss.item()\n",
    "\n",
    "\t\tif backward is True:\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\tloss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\t\t\n",
    "\tavg_loss = total_loss / len(data_loader)\n",
    "\treturn avg_loss\n",
    "\n",
    "\n",
    "def one_pass_acc(model, dataloader, num_points):\n",
    "    model.eval()\n",
    "    total_incorrect = 0\n",
    "    \n",
    "    for x, y in dataloader:\n",
    "        y_pred = torch.sigmoid(model(x))\n",
    "        \n",
    "        # summing up all the incorrect examples by taking difference and adding up all non-zero entries\n",
    "        total_incorrect += torch.sum(torch.abs(y - y_pred)).item()\n",
    "        \n",
    "    percent_wrong = total_incorrect / num_points\n",
    "    return 1 - percent_wrong * 0.01\n",
    "\n",
    "\n",
    "def training(model: model, data_loader: DataLoader, loss_fun: List[float], optimizer, num_epoch: int) -> torch.float:\n",
    "\t\n",
    "\tfor i in tqdm(range(num_epoch)):\n",
    "\n",
    "\t\ttrain_loss = one_pass(model=model, data_loader=train_dl, backward=True, loss_fun=loss_fun, optimizer=optimizer)\n",
    "\t\tval_loss = one_pass(model=model, data_loader=val_dl, backward=False,loss_fun=loss_fun, optimizer=optimizer)\n",
    "\t\tval_acc = one_pass_acc(model, val_dl, len(val_dl))\n",
    "\t\tprint(f\"epoch: {i+1 :<3} train_loss: {train_loss:.9f} val_loss: {val_loss:.9f} val_acc: {val_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T06:19:57.250749Z",
     "start_time": "2021-10-08T06:11:11.978722Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 1/5 [01:44<06:58, 104.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.92795658111572 33622.60497188568 991\n",
      "epoch: 1   train_loss: 0.577789194 val_loss: 0.654867937 val_acc: 0.661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [03:29<05:14, 104.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.43515807324052 33134.24165058136 991\n",
      "epoch: 2   train_loss: 0.569949154 val_loss: 0.543030148 val_acc: 0.666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [05:13<03:29, 104.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.39662631465015 32105.0566778183 991\n",
      "epoch: 3   train_loss: 0.563154364 val_loss: 0.522036364 val_acc: 0.676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [06:58<01:44, 104.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.41755041128211 35098.79245758057 991\n",
      "epoch: 4   train_loss: 0.561065788 val_loss: 0.606141038 val_acc: 0.646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [08:45<00:00, 105.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.0127964977299 32715.681329250336 991\n",
      "epoch: 5   train_loss: 0.556925718 val_loss: 0.536652711 val_acc: 0.670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loss_fun = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "training(model = model, data_loader = train_dl, loss_fun = loss_fun, optimizer = optimizer, num_epoch = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2c92c0f5c20d043a0775370d75da3ea77e872044c5f7882bcf4e22c0e1be6e92"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
